confluence page: 
https://vmw-confluence.broadcom.net/spaces/~wlam/pages/2228281458/VCF+9+Offline+Depot+Setup+for+Internal+Broadcom

run 
python3 build_vcf_dir.py
to make the directories from the json file

use wget in spider mode easier
wget --spider -r -np -nH --cut-dirs=8 -R "*" -P /root/tonjiak/playbooks/vcf9/offlindedepot/depot/vcf9.01/PROD http://build-squid.vcfd.broadcom.net/build/mts/release/bora-24966933/publish/PROD/

open to 
http://build-squid.vcfd.broadcom.net/build/mts/release/bora-24966933/publish/PROD/

open console F12
paste below code

(async function crawl() {
    let folderSet = new Set();
    async function getFolders(url) {
        try {
            let response = await fetch(url);
            let text = await response.text();
            let parser = new DOMParser();
            let doc = parser.parseFromString(text, 'text/html');
            let links = Array.from(doc.querySelectorAll('a'))
                .map(a => a.getAttribute('href'))
                .filter(href => href && href.endsWith('/') && !href.startsWith('..') && !href.startsWith('/'));
            
            for (let link of links) {
                let fullPath = new URL(link, url).href;
                let relativePath = fullPath.split('/PROD/')[1];
                if (relativePath) {
                    folderSet.add(relativePath);
                    await getFolders(fullPath); // Recurse into subfolders
                }
            }
        } catch (e) { console.error("Error crawling " + url); }
    }
    
    console.log("Crawling... please wait...");
    await getFolders(window.location.href);
    
    let targetRoot = "/root/tonjiak/playbooks/vcf9/offlinedepot/depot/vcf9.01/PROD/";
    let output = Array.from(folderSet).map(f => `mkdir -p "${targetRoot}${f}"`).join('\n');
    
    console.clear();
    console.log("--- COPY THE COMMANDS BELOW ---");
    console.log(output);
})();